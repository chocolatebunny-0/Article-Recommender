# -*- coding: utf-8 -*-
"""subtask3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eDiAIXdFQ1OE5btVXF6oRmRLWtG6434_
"""

!pip install mysql-connector-python

import pandas as pd
import numpy as np
import mysql.connector
from sqlalchemy import create_engine
import sys
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
import pickle



#defining a function that returns keywords from title
def keywords(title):
    ''' function that recieves title and return the keywords ''' 

    title = [title]
    
    tfidf = TfidfVectorizer(stop_words='english')
    tfidf.fit_transform(title)
        
    return " ".join(tfidf.get_feature_names())

# call function
keywords("Learning Web development at StartNg")

#reading the dataframe from sqlDB
mydb = mysql.connector.connect(host="remotemysql.com",
                              user="8SawWhnha4",
                              passwd="zFvOBIqbIz",
                              database="8SawWhnha4")
engine = create_engine('mysql+mysqlconnector://8SawWhnha4:zFvOBIqbIz@remotemysql.com/8SawWhnha4')

df = pd.read_sql_query('select title from posts where id>50 LIMIT 10', engine)

df['title'] = df['title'].replace({"'ll": " "}, regex=True)

df['keywords'] = None
#trying to get keywords from a specific column in df
for i in range(len(df)):
    df.iat[i, df.columns.get_loc("keywords")] = keywords(df.iat[i,0])
    
art_title= [df.iat[i,1] for i  in range(len(df))]
tfidf = TfidfVectorizer(stop_words='english')
t_matrix = tfidf.fit_transform(art_title)

#using k-means to create clusters
MODEL = KMeans(n_clusters=5,init='k-means++', n_init=15, max_iter=300,random_state=None)
#unpack the dataframe and matrix

# Fit the k-means object with tfidf_matrix
MODEL.fit(t_matrix)

CLUSTERS = MODEL.labels_.tolist()

# Create a column cluster to denote the generated cluster for each article
df["CLUSTER"] = CLUSTERS

# Display number of articles  per cluster (clusters from 0 to 4)
df['CLUSTER'].value_counts()

#to save this model 
FILE_NAME ='built_model.sav'
pickle.dump(CLUSTERS, open(FILE_NAME, 'wb'))

#to load saved model later
GET_SAVED = pickle.load(open(FILE_NAME, 'rb'))
print(GET_SAVED)
