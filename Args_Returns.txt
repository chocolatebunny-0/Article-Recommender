TASK 1
def post(p_id):
    """ Function to get an article title from the title field given a post ID """
 """ Function to get an article title from the title field given a post ID
    Args: The post id
    Returns: A particular post title with id = post_id"""
    return POSTS[POSTS['post_id'] == p_id]['title'].tolist()[0].split(' - ')[0]


def recommend(post_id, num):
    """ Function to reads the results out of the dictionary. """
    """ Function to reads the results out of the dictionary.
    Args: post id and number of recommendations required
    Returns: Dictionary of similar titles and score"""
    print("Recommending " + str(num) + " articles similar to " + post(post_id) + "...")
    print("--------------------------------------------------------------------------")
    recs = RESULTS[post_id][:num]



TASK 2
''' module for getting keywords from a title '''
 """ module for getting keywords from a title
    Args: Title
    Returns:Keywords of the title"""
from sklearn.feature_extraction.text import TfidfVectorizer
def keywords(title):

    ''' function that receives title and return the keywords '''
""" function that receives title and return the keywords
    Args: Title
    Returns:all keywords from the title"""
    # turn input to list to be analysed
    title = [title]

 ''' function that removes all english stop words such as 'the', 'a' '''
""" function removes all english stop words such as 'the', 'a'
    Args: stop words
    Returns:text or article without stopwords"""
    tfidf = TfidfVectorizer(stop_words='english')

 

    '''function that constructs the required TF-IDF matrix by tokenizing and transforming the data '''
"""'function that constructs the required TF-IDF matrix by tokenizing and transforming the data 
    Args: stop words
    Returns:string of title keywords"""
    tfidf.fit_transform(title)
    # return an string of keywords from the title
    return " ".join(tfidf.get_feature_names())

 ''' call function '''
"""'call function
    Args: stop words
    Returns:library of stopwords"""
print(keywords("at a"))


TASK 3
 ''' function that receives title and returns the keywords ''' 
"""'function that receives title and returns the keywords
    Args: title
    Returns:library of stopwords"""
def keywords(title):

    title = [title]
    
    tfidf = TfidfVectorizer(stop_words='english')
    tfidf.fit_transform(title)
        
    return " ".join(tfidf.get_feature_names())

 '''call function '''
"""'call function
    Args: keyword
    Returns:library of stopwords"""
keywords("Learning Web development at StartNg")

 '''Function reading the dataframe from sqlDB '''
"""'Function reading dataframe from sqlDB
    Args: keyword from dataframe in the database
    Returns:stopwords"""

mydb = mysql.connector.connect(host="remotemysql.com",
                              user="8SawWhnha4",
                              passwd="zFvOBIqbIz",
                              database="8SawWhnha4")
engine = create_engine('mysql+mysqlconnector://8SawWhnha4:zFvOBIqbIz@remotemysql.com/8SawWhnha4')

df = pd.read_sql_query('select title from posts where id>50 LIMIT 10', engine)

df['title'] = df['title'].replace({"'ll": " "}, regex=True)

df['keywords'] = None

'''Function to get keywords from a specific column in df'''
"""''function to get keywords from a specific column in df
    Args: Keywords from dataframe in the database
    Returns:words from the column"""
for i in range(len(df)):
    df.iat[i, df.columns.get_loc("keywords")] = keywords(df.iat[i,0])
    
art_title= [df.iat[i,1] for i  in range(len(df))]
tfidf = TfidfVectorizer(stop_words='english')
t_matrix = tfidf.fit_transform(art_title)

'''Function using k-means to create clusters'''
"""''function to use k-means to create clusters
    Args: keywords
    Returns:matrix"""

MODEL = KMeans(n_clusters=5,init='k-means++', n_init=15, max_iter=300,random_state=None)
#unpack the dataframe and matrix

# Fit the k-means object with tfidf_matrix
MODEL.fit(t_matrix)

CLUSTERS = MODEL.labels_.tolist()

'''Function to create a column cluster to denote the generated cluster for each article'''
"""''function to create a column cluster to denote the generated cluster for each article
    Args: dataframe
    Returns:clustered articles"""

df["CLUSTER"] = CLUSTERS

''' Function to display number of articles  per cluster (clusters from 0 to 4)'''
"""'' Function to display number of articles  per cluster (clusters from 0 to 4)
    Args: cluster
    Returns: listed cluster articles"""
df['CLUSTER'].value_counts()

'''Function to save this model'''
"""'' Function to save the model
    Args: model
    Returns: recommender model"""
FILE_NAME ='built_model.sav'
pickle.dump(CLUSTERS, open(FILE_NAME, 'wb'))

'''Function to load saved model later'''
"""''Function to load saved model later
    Args: model
    Returns: recommender model"""

GET_SAVED = pickle.load(open(FILE_NAME, 'rb'))
print(GET_SAVED)



TASK 4
""" Function that takes in title of an article and predicts similar articles to users """
# **Step 1 - Train the engine.**
#
# Create a TF-IDF matrix of unigrams, bigrams, and trigrams for each product.
# The 'stop_words' param tells the TF-IDF module to ignore common english words like 'the', etc.
#
# Then we compute similarity between all articles using SciKit Leanr's linear_kernel
# (which in this case is equivalent to cosine similarity).
#
# Iterate through each article's similar articles and store the 100 most-similar.
# You could show more than 100, your choice.
#
# Similarities and their scores are stored in a dictionary as a list of Tuples,
# indexed to their post id

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel
import mysql.connector
from sqlalchemy import create_engine

#loading the dataset
MYDB = mysql.connector.connect(host="remotemysql.com", user="8SawWhnha4", passwd="zFvOBIqbIz",
                               database="8SawWhnha4")

ENGINE = create_engine('mysql+mysqlconnector://8SawWhnha4:zFvOBIqbIz@remotemysql.com/8SawWhnha4')

#fetching the tables in the dataset
DB_CURSOR = MYDB.cursor()
DB_CURSOR.execute('show tables')
for table in DB_CURSOR:
    print(table)

#checking out the post table
POSTS = pd.read_sql_query('select * from posts', ENGINE)
POSTS.drop(['user_id', 'tags', 'slug', 'created_at', 'updated_at', 'image',
            'status_id', 'action', 'post_id'], axis=1, inplace=True)
POSTS.rename(columns={"id":"post_id"}, inplace=True)
POSTS.head(50)

TF = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), min_df=0, stop_words='english')
TFIDF_MATRIX = TF.fit_transform(POSTS['title'])

COSINE_SIMILARITIES = linear_kernel(TFIDF_MATRIX, TFIDF_MATRIX)

RESULTS = {}

for idx, row in POSTS.iterrows():
    similar_indices = COSINE_SIMILARITIES[idx].argsort()[:-100:-1]
    similar_items = [(COSINE_SIMILARITIES[idx][i], POSTS['post_id'][i]) for i in similar_indices]

    # First post is the post itself, so remove it.
    # Each dictionary entry is like: [(1,2), (3,4)], with each tuple being (score, post_id)
    RESULTS[row['post_id']] = similar_items[1:]
print('done!')

def post(p_id):
    """ Function to get an article title from the title field,
    given a post ID 
    Args: The post id
    Arg type: Integer
    Returns: A particular post title with id = post_id"""
    return POSTS[POSTS['post_id'] == p_id]['title'].tolist()[0].split(' - ')[0]


def recommend(post_id, num):
    """ Function to reads the results out of the dictionary.
    Args: post id and number of recommendations required
    Arg type: Integer, Integer
    Returns: Dictionary of similar titles and score"""
    print("Recommending " + str(num) + " articles similar to " + post(post_id) + "...")
    print("--------------------------------------------------------------------------")
    recs = RESULTS[post_id][:num]
    for rec in recs:
        print("Recommended: " + post(rec[1]) + " (score:" + str(rec[0]) + ")")

# Just plug in any post id here (we have about 800 posts in the dataset), and the number of recommendations you want (1-99)
# You can get a list of valid post IDs by evaluating the variable 'POSTS'

recommend(post_id=33, num=5)
